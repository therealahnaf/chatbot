import os
import json
from typing import Annotated, Literal, TypedDict, Optional, List
from dotenv import load_dotenv

load_dotenv()

from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, StateGraph, MessagesState
from langchain_core.tools import tool
from langchain_core.messages import ToolMessage, SystemMessage, AIMessage, HumanMessage
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from app.formzed.service.schema_loader import resolve_reference

# Load the vector database
DB_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), "vector_db")
try:
    embeddings = OpenAIEmbeddings()
    vector_db = FAISS.load_local(DB_PATH, embeddings, allow_dangerous_deserialization=True)
except Exception as e:
    print(f"Error loading vector database: {e}")
    vector_db = None

# --- State Definition ---
class EditState(MessagesState):
    final_json: Optional[str] # The current valid JSON
    edit_plan: Optional[str] # The plan submitted by the conversing agent
    new_json: Optional[str] # The new JSON generated by the editing agent

# --- Tools for Editing Agent ---
@tool
def resolve_schema_reference_tool(reference: str):
    """
    Resolve a specific schema reference to get its full definition and properties.
    Args:
        reference: The reference string, e.g., "#page", "#panel", "#text", "#rating".
    """
    if not reference.startswith("#"):
        reference = f"#{reference}"
    result = resolve_reference(reference)
    if "error" in result:
        return result["error"]
    return json.dumps(result, indent=2)

@tool
def search_schema_index(query: str):
    """
    Search the master index (documentation) for information about SurveyJS elements, properties, and concepts.
    Use this to understand WHAT elements are available and HOW they work before using them.
    """
    if vector_db is None:
        return "Error: Vector database is not available."
    
    try:
        results = vector_db.similarity_search(query, k=3)
        return "\n\n---\n\n".join([doc.page_content for doc in results])
    except Exception as e:
        return f"Error during search: {e}"

editing_tools = [resolve_schema_reference_tool, search_schema_index]

# --- Tools for Conversing Agent ---
@tool
def submit_edit_plan(plan: str):
    """
    Submit the detailed plan for editing the survey.
    Use this when you have understood what changes the user wants to make.
    The plan should be specific and actionable for the editing agent.
    """
    return "Edit plan submitted successfully."

conversing_tools = [submit_edit_plan]

# --- Models ---
conversing_model = ChatOpenAI(model="gpt-4o-mini", temperature=0).bind_tools(conversing_tools)
editing_model = ChatOpenAI(model="gpt-4o-mini", temperature=0).bind_tools(editing_tools)

# --- Prompts ---
CONVERSING_SYSTEM_PROMPT = """You are the Survey Editor Assistant.
Your goal is to converse with the user to understand what changes they want to make to their existing survey.

Current Survey Context:
The user has a valid survey JSON. You do not need to rewrite it yourself.
Your job is to clarify the user's intent.

Responsibilities:
1.  **Understand the Request**: Listen to the user's change request (e.g., "Add a question asking for email", "Change the title to 'Feedback'").
2.  **Clarify**: If the request is vague, ask for details (e.g., "Where should the email question go?", "Is it required?").
3.  **Submit Plan**: Once you have a clear understanding of the *what* and *where*, call the `submit_edit_plan` tool with a detailed description of the changes.
    *   DO NOT format your answers with numbers or bullet points.
    *   Ask the user ONE question at a time.
    *   NEVER ask more than ONE question at a time.

Example Plan:
"Add a text question named 'q_email' with title 'Email Address' to 'page_1'. Make it required and add an email validator."

Do NOT generate the JSON yourself. Just create the plan.
"""

EDITING_SYSTEM_PROMPT = """You are the Survey JSON Editor.
Your goal is to apply the requested edits to the survey JSON and return the NEW valid JSON.

Inputs:
1.  `final_json`: The current state of the survey.
2.  `edit_plan`: The instructions for what to change.

Responsibilities:
1.  **Analyze**: Read the `edit_plan` and the `final_json`.
2.  **Consult Schema**: Use `search_schema_index` or `resolve_schema_reference_tool` if you need to know how to structure a new element or property.
3.  **Apply Edits**: Modify the JSON to implement the plan.
    *   Preserve existing structure unless asked to change it.
    *   Ensure unique names for new elements.
4.  **Output**: Return ONLY the full, valid, updated JSON string.
"""

# --- Nodes ---

def run_conversing_agent(state: EditState):
    print("--- Running Edit Conversing Agent ---")
    messages = state["messages"]
    
    # We might want to inject the current JSON summary into the system prompt or messages if it's not too large.
    # For now, let's assume the agent knows it exists. 
    # Optionally, we could add a system message with a summary of the current JSON.
    
    messages_with_system = [SystemMessage(content=CONVERSING_SYSTEM_PROMPT)] + messages
    response = conversing_model.invoke(messages_with_system)
    print(f"[Edit Conversing] Response: {response.content}")
    
    return {"messages": [response]}

def run_conversing_tools(state: EditState):
    print("--- Running Edit Conversing Tools ---")
    messages = state["messages"]
    last_message = messages[-1]
    
    tool_calls = last_message.tool_calls
    tool_messages = []
    state_update = {}
    
    for tool_call in tool_calls:
        tool_name = tool_call["name"]
        tool_args = tool_call["args"]
        
        if tool_name == "submit_edit_plan":
            print(f"[Edit Conversing] Submitting plan: {tool_args.get('plan')}")
            state_update["edit_plan"] = tool_args.get("plan")
            tool_messages.append(ToolMessage(content="Plan submitted.", tool_call_id=tool_call["id"]))
            
    state_update["messages"] = tool_messages
    return state_update

def extract_json(text):
    import re
    text = text.strip()
    match = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match: return match.group(1)
    match = re.search(r"```\s*(\{.*?\})\s*```", text, re.DOTALL)
    if match: return match.group(1)
    match = re.search(r"(\{.*\})", text, re.DOTALL)
    if match: return match.group(1)
    return text

def run_editing_agent(state: EditState):
    print("--- Running Edit Executor Agent ---")
    current_json = state.get("final_json")
    edit_plan = state.get("edit_plan")
    
    messages = [
        SystemMessage(content=EDITING_SYSTEM_PROMPT),
        HumanMessage(content=f"Current JSON:\n```json\n{current_json}\n```\n\nEdit Plan:\n{edit_plan}")
    ]
    
    # Simple loop for tools if needed, similar to agent_c's execute_tools_loop
    # But here we can use a simpler approach or reuse the loop logic.
    # Let's implement a small loop here.
    
    response = editing_model.invoke(messages)
    messages.append(response)
    
    max_iterations = 10
    for i in range(max_iterations):
        if not response.tool_calls:
            break
        
        print(f"[Edit Executor] Tool loop {i+1}")
        tool_outputs = []
        for tc in response.tool_calls:
            if tc["name"] == "resolve_schema_reference_tool":
                res = resolve_schema_reference_tool.invoke(tc["args"])
            elif tc["name"] == "search_schema_index":
                res = search_schema_index.invoke(tc["args"])
            else:
                res = "Unknown tool"
            tool_outputs.append(ToolMessage(content=str(res), tool_call_id=tc["id"]))
        
        messages.extend(tool_outputs)
        response = editing_model.invoke(messages)
        messages.append(response)
    
    # Extract JSON from final response
    try:
        content = extract_json(response.content)
        # Verify it loads
        json.loads(content)
        print("[Edit Executor] JSON generated successfully.")
        return {"new_json": content, "messages": [AIMessage(content="I have applied the edits.")]}
    except Exception as e:
        print(f"[Edit Executor] Failed to generate valid JSON: {e}")
        return {"messages": [AIMessage(content=f"Error applying edits: {e}")]}

# --- Routing ---

def route_conversing(state: EditState):
    messages = state["messages"]
    last_message = messages[-1]
    if last_message.tool_calls:
        return "conversing_tools"
    return END

def route_conversing_tools(state: EditState):
    if state.get("edit_plan"):
        return "editing_agent"
    return "conversing_agent"

# --- Graph ---

def get_graph(checkpointer=None):
    workflow = StateGraph(EditState)
    
    workflow.add_node("conversing_agent", run_conversing_agent)
    workflow.add_node("conversing_tools", run_conversing_tools)
    workflow.add_node("editing_agent", run_editing_agent)
    
    workflow.add_edge(START, "conversing_agent")
    
    workflow.add_conditional_edges("conversing_agent", route_conversing)
    workflow.add_conditional_edges("conversing_tools", route_conversing_tools)
    
    # After editing agent, we end this sub-graph. 
    # The main graph will pick up the 'new_json' and route to validation.
    workflow.add_edge("editing_agent", END)
    
    return workflow.compile(checkpointer=checkpointer)
